{
  "name": "ai-inference-engine",
  "version": "1.0.0",
  "description": "AI Model Inference Engine with ONNX Runtime",
  "main": "src/server.js",
  "scripts": {
    "start": "node src/server.js",
    "dev": "nodemon src/server.js",
    "test": "jest --coverage",
    "test:watch": "jest --watch"
  },
  "keywords": [
    "ai",
    "inference",
    "onnx",
    "machine-learning"
  ],
  "author": "",
  "license": "MIT",
  "dependencies": {
    "axios": "^1.12.2",
    "axios-retry": "^4.5.0",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "express": "^4.18.2",
    "helmet": "^7.1.0",
    "morgan": "^1.10.0",
    "multer": "^2.0.2",
    "onnxruntime-node": "^1.16.3",
    "sharp": "^0.33.0",
    "winston": "^3.11.0"
  },
  "devDependencies": {
    "jest": "^29.7.0",
    "nodemon": "^3.0.1",
    "supertest": "^6.3.3"
  },
  "engines": {
    "node": ">=18.0.0"
  }
}
